{
 "metadata": {
  "name": "",
  "signature": "sha256:c16d9af28f82c0bac13a8db768cbdba2cdcf6e277e8abf87422682e0733fce4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gene Expression Omnibus (GEO)\n",
      "=============================\n",
      "\n",
      "Import public data from NCBI Gene Expression Omnibus (GEO). [Martin A. Fitzpatrick][]\n",
      "\n",
      "Introduction\n",
      "------------\n",
      "\n",
      "This plugin supports loading in data from NCBI GEO using the standard SOFT format. Loading prepared datasets will import class labels and supporting information.\n",
      "\n",
      "Quick start\n",
      "-----------\n",
      "\n",
      "Download a sample database from the [Gene Expression Omnibus][] in SOFT format. Import the data using this plugin\n",
      "\n",
      "  [Martin A. Fitzpatrick]: http://martinfitzpatrick.name/\n",
      "  [Gene Expression Omnibus]: http://www.ncbi.nlm.nih.gov/geo/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "import os\n",
      "import csv\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from biocyc import biocyc\n",
      "biocyc.set_organism('HUMAN')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess_soft(reader, f=None):\n",
      "    # Preprocess into the chunks (then can manageable process them in turn)\n",
      "    soft_data = defaultdict(list)\n",
      "    for n, row in enumerate(reader):\n",
      "        if row[0].startswith('^'):  # Control row\n",
      "            section = row[0]\n",
      "            continue\n",
      "        soft_data[section].append(row)\n",
      "\n",
      "    return soft_data\n",
      "\n",
      "def get_soft_metadata(rows, while_starts_with='!'):\n",
      "\n",
      "    metadata = {}\n",
      "\n",
      "    for row in rows:\n",
      "        if not row[0].startswith('!'):\n",
      "            break\n",
      "\n",
      "        key, value = row[0][1:].split(' = ')  # Remove the ! and then split, removing the ' = '\n",
      "        metadata[key] = value\n",
      "\n",
      "    return metadata\n",
      "\n",
      "def get_float(x):\n",
      "    try:\n",
      "        x = float(x)\n",
      "    except:\n",
      "        if x == 'null':\n",
      "            x = None\n",
      "    return x\n",
      "\n",
      "def get_soft_data(rows, starts, ends):\n",
      "    headers = False\n",
      "    data = {}\n",
      "    headers_at = False\n",
      "    for n, row in enumerate(rows):\n",
      "        if row[0] == starts:\n",
      "            headers_at = n + 1\n",
      "            start_at = n + 2\n",
      "            break\n",
      "\n",
      "    if not headers_at:\n",
      "        return False\n",
      "\n",
      "    headers = rows[headers_at]\n",
      "\n",
      "    for row in rows[start_at:]:\n",
      "        if row[0] == ends:\n",
      "            break\n",
      "\n",
      "        # Rewrite to account for null values; skip header (left column)\n",
      "        row_data = row\n",
      "        #row_data[1:] = [get_float(x) for x in row[1:]]\n",
      "        data[row[0]] = dict(list(zip(headers, row_data)))\n",
      "\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOFT files are a /sort of/ bastardized csv with data in tab-separated columns\n",
      "# So, we use the csv reader to get that, accounting for most stuff being single field with\n",
      "# slightly strange identifiers\n",
      "with open(config['filename'], 'rU') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t', dialect='excel')\n",
      "\n",
      "    soft_data = preprocess_soft(reader, f=f)\n",
      "    # soft_data now contains lists of sections with ^ markers\n",
      "\n",
      "    database = {}\n",
      "    dataset = {}\n",
      "    dataset_data = {}\n",
      "    subsets = {}\n",
      "\n",
      "    for section, rows in list(soft_data.items()):\n",
      "\n",
      "        if section.startswith('^DATABASE'):\n",
      "            database = get_soft_metadata(rows)\n",
      "\n",
      "        elif section.startswith('^DATASET'):\n",
      "            dataset.update(get_soft_metadata(rows))  # update because seems can be >1 entry to dataset\n",
      "            data = get_soft_data(rows, '!dataset_table_begin', '!dataset_table_end')\n",
      "            dataset_data = data\n",
      "\n",
      "        elif section.startswith('^SUBSET'):\n",
      "            key, subset_id = section.split(' = ')\n",
      "            subsets[subset_id] = get_soft_metadata(rows)\n",
      "            subsets[subset_id]['subset_sample_id'] = subsets[subset_id]['subset_sample_id'].split(',')  # Turn to list of ids\n",
      "\n",
      "    # We now have the entire dataset loaded; but in a bit of a messed up format\n",
      "    # Build a dataset object to fit and map the data in\n",
      "    sample_ids = []\n",
      "    for k, subset in list(subsets.items()):\n",
      "        sample_ids.extend(subset['subset_sample_id'])\n",
      "    sample_ids = sorted( list( set(sample_ids) ) )   # Get the samples sorted so we keep everything lined up\n",
      "\n",
      "    class_lookup = {}\n",
      "    for class_id, s in list(subsets.items()):\n",
      "        for s_id in s['subset_sample_id']:\n",
      "            class_lookup[s_id] = \"%s (%s)\" % (s['subset_description'] if 'subset_description' in s else '', class_id)\n",
      "\n",
      "    xdim = len(dataset_data)  # Use first sample to access the gene list\n",
      "    ydim = len(sample_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've loaded the data now and have all entity info etc. so construct a Pandas dataframe for output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.zeros((ydim, xdim))\n",
      "gene_ids = sorted(dataset_data.keys())  # Get the keys sorted so we keep everything lined up\n",
      "\n",
      "for xn, gene_id in enumerate(gene_ids):\n",
      "    for yn, sample_id in enumerate(sample_ids):\n",
      "\n",
      "        data[yn, xn] = float( dataset_data[gene_id][sample_id] )\n",
      "# = Entrez Gene identifier\n",
      "#UniGene title = Entrez UniGene name\n",
      "#UniGene symbol = Entrez UniGene symbol\n",
      "#UniGene ID = Entrez UniGene identifier\n",
      "#Nucleotide Title = Entrez Nucleotide title\n",
      "#GI = GenBank identifier\n",
      "\n",
      "output_data = pd.DataFrame(data)\n",
      "output_data.index = pd.MultiIndex.from_tuples( zip( sample_ids, [class_lookup[s_id] for s_id in sample_ids]), names=['Sample','Class'] )\n",
      "# build column index from possible sets\n",
      "index_tuples = []\n",
      "passthru = lambda x: x\n",
      "headers = [\n",
      "    ('IDENTIFIER', passthru, 'Label'),\n",
      "    ('Gene ID', passthru, 'Entrez Gene'),\n",
      "    ('UniGene ID', passthru, 'UNIGENE'),\n",
      "    ('IDENTIFIER', lambda x: biocyc.find_gene_by_name(x),'BioCyc') # Auto-map to BioCyc\n",
      "]\n",
      "for n, gene_id in enumerate(gene_ids):\n",
      "    \n",
      "    t = tuple([n,] + [ fn(dataset_data[gene_id][cl]) for cl, fn, ci in headers if cl in dataset_data[gene_id]])\n",
      "    index_tuples.append(t)\n",
      "\n",
      "index_names = ['Measurement'] + [ci for cl, fn, ci in headers if cl in dataset_data[gene_id]]\n",
      "output_data.columns = pd.MultiIndex.from_tuples( index_tuples, names=index_names )\n",
      "#output_data.columns = [dataset_data[gene_id]['IDENTIFIER'] for gene_id in gene_ids]\n",
      "output_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate simple result figure (using pathomx libs)\n",
      "from pathomx.figures import spectra\n",
      "\n",
      "View = spectra(output_data, styles=styles);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}