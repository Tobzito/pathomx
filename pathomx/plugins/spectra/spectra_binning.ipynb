{
 "metadata": {
  "name": "",
  "signature": "sha256:296c45174e8fa445138b95535767b3a47dbb0235cfbe2998c04dfc41f0bb489b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Binning\n",
      "=======\n",
      "\n",
      "Data pre-processing technique to reduce minor observation errors and reduce data size.  \n",
      "[Martin A. Fitzpatrick][]\n",
      "\n",
      "Introduction\n",
      "------------\n",
      "\n",
      "Data binning is a widely used data pre-processing technique that can be used to reduce the effects of minor observational errors. It can also be used to reduce the size of a dataset for easier processing. Regions of the data (bins) are defined, within which data is replaced with a representative value, e.g. a mean, median or central value. It is a form of quantization.\n",
      "\n",
      "It is important to remember that binning results in a loss of data, and may introduce artefacts. This plugin attempts to mitigate some of these problems by providing information on data loss, and offering adaptive binning approaches.\n",
      "\n",
      "Quick start\n",
      "-----------\n",
      "\n",
      "This plugin can bin any data in 1 dimension, e.g. NMR spectra. Simply select the data source and the data will be automatically binned. You can adjust the bin size using the toolbar, together with a bin offset. You can view the result of the binning a tabular, or spectral view. Importantly, this plugin also presents a difference view that shows the data loss associated with a given binning strategy, together with a summary view.\n",
      "\n",
      "Tip\n",
      "---\n",
      "\n",
      "Resulting data output can be fed into statistical analysis, for example PCA, where the effects of binning can be observed live.\n",
      "\n",
      "  [Martin A. Fitzpatrick]: http://martinfitzpatrick.name/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "if input_data is None:\n",
      "    raise Exception('No input data')\n",
      "\n",
      "if type(input_data.columns) == pd.Index:\n",
      "    scale = input_data.columns.values\n",
      "elif type(input_data.columns) == pd.MultiIndex:\n",
      "    try:\n",
      "        scidx = input_data.columns.names.index('ppm')\n",
      "    except:\n",
      "        scidx = input_data.columns.names.index('Label')\n",
      "        \n",
      "    scale = [c[scidx] for c in input_data.columns.values]\n",
      "    \n",
      "r = np.nanmin(scale), np.nanmax(scale)\n",
      "\n",
      "bin_size, bin_offset = config.get('bin_size'), config.get('bin_offset')\n",
      "\n",
      "bins = np.arange(r[0] + bin_offset, r[1] + bin_offset, bin_size)\n",
      "number_of_bins = len(bins) - 1\n",
      "\n",
      "# Can't increase the size of data, if bins > current size return the original\n",
      "if number_of_bins >= len(scale):\n",
      "    output_data = input_data\n",
      "\n",
      "else:\n",
      "    \n",
      "    output_data = pd.DataFrame( np.zeros(( input_data.shape[0], number_of_bins) ) )\n",
      "\n",
      "    for n, d in enumerate(input_data.values):\n",
      "        binned_data = np.histogram(scale, bins=bins, weights=d)\n",
      "        binned_num = np.histogram(scale, bins=bins) # Number of data points that ended up contributing to each bin\n",
      "        output_data.ix[n, :] = binned_data[0] / binned_num[0] # Mean\n",
      "\n",
      "    new_scale = [float(x) for x in binned_data[1][:-1]]\n",
      "    \n",
      "    # Binning is low->high only, if the resulting scale is reversed to the source data flip it and the data\n",
      "    original_dir = (scale[0] - scale[1]) / abs((scale[0] - scale[1]))\n",
      "    new_dir = (new_scale[0] - new_scale[1]) / abs((new_scale[0] - new_scale[1]))\n",
      "    \n",
      "    if original_dir != new_dir: # Flip horizontal\n",
      "        \n",
      "        new_scale = new_scale[::-1]\n",
      "        for n, d in enumerate(output_data.values):\n",
      "            output_data.ix[n, :] = np.fliplr( np.reshape(d, (-1, number_of_bins)) ) \n",
      "    \n",
      "    output_data.columns = pd.Index(new_scale, name='Scales')\n",
      "    output_data.index = input_data.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate simple result figure (using pathomx libs)\n",
      "from pathomx.figures import spectra\n",
      "\n",
      "View = spectra(output_data, styles=styles);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}