{
 "metadata": {
  "name": "",
  "signature": "sha256:0369152fde55d78f47320aa493ed4c5f2b1a4ec08d64be6b141358e009505b0f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Binning\n",
      "=======\n",
      "\n",
      "Data pre-processing technique to reduce minor observation errors and reduce data size.  \n",
      "[Martin A. Fitzpatrick][]\n",
      "\n",
      "Introduction\n",
      "------------\n",
      "\n",
      "Data binning is a widely used data pre-processing technique that can be used to reduce the effects of minor observational errors. It can also be used to reduce the size of a dataset for easier processing. Regions of the data (bins) are defined, within which data is replaced with a representative value, e.g. a mean, median or central value. It is a form of quantization.\n",
      "\n",
      "It is important to remember that binning results in a loss of data, and may introduce artefacts. This plugin attempts to mitigate some of these problems by providing information on data loss, and offering adaptive binning approaches.\n",
      "\n",
      "Quick start\n",
      "-----------\n",
      "\n",
      "This plugin can bin any data in 1 dimension, e.g. NMR spectra. Simply select the data source and the data will be automatically binned. You can adjust the bin size using the toolbar, together with a bin offset. You can view the result of the binning a tabular, or spectral view. Importantly, this plugin also presents a difference view that shows the data loss associated with a given binning strategy, together with a summary view.\n",
      "\n",
      "Tip\n",
      "---\n",
      "\n",
      "Resulting data output can be fed into statistical analysis, for example PCA, where the effects of binning can be observed live.\n",
      "\n",
      "  [Martin A. Fitzpatrick]: http://martinfitzpatrick.name/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Abs the data (so account for negative peaks also)\n",
      "data_a = input_data.abs()\n",
      "# Sum each spectra (TSA)\n",
      "data_as = data_a.sum()\n",
      "# Identify median\n",
      "median_s = data_as.median()\n",
      "# Scale others to match (*(median/row))\n",
      "scaling = median_s / data_as\n",
      "# Scale the spectra\n",
      "tsa_data = input_data * scaling\n",
      "\n",
      "if config['algorithm'] == 'TSA':\n",
      "    output_data = tsa_data\n",
      "    \n",
      "elif config['algorithm'] == 'PQN':\n",
      "    # Take result of TSA normalization    \n",
      "    # Calculate median spectrum (median of each variable)\n",
      "    median_s = np.median(tsa_data, axis=0)\n",
      "    # For each variable of each spectrum, calculate ratio between median spectrum variable and that of the considered spectrum\n",
      "    spectra_r = median_s / np.abs(input_data)\n",
      "    # Take the median of these scaling factors and apply to the entire considered spectrum\n",
      "    output_data = input_data * np.median(spectra_r, axis=1).reshape(-1, 1)\n",
      "    \n",
      "    \n",
      "data = None; # Clear so not expored\n",
      "data_a = None;\n",
      "data_as = None;\n",
      "media_as = None;\n",
      "scaling = None;\n",
      "spectra_r = None;\n",
      "tsa_data = None;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate simple result figure (using pathomx libs)\n",
      "from pathomx.figures import spectra\n",
      "\n",
      "View = spectra(output_data, styles=styles);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}